<!DOCTYPE html><html lang="en"> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/icon" href="/favicon.ico"><meta name="generator" content="Astro v4.11.5"><!-- Canonical URL --><link rel="canonical" href="https://rezvan.xyz/cityu/cs4487/cs4487/"><!-- Primary Meta Tags --><title>Part 1 - Introduction | machine learning | rezvan.xyz</title><meta name="title" content="Part 1 - Introduction | machine learning | rezvan.xyz"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://rezvan.xyz/cityu/cs4487/cs4487/"><meta property="og:title" content="Part 1 - Introduction | machine learning | rezvan.xyz"><meta property="og:description"><meta property="og:image" content="https://rezvan.xyz/favicon.ico"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://rezvan.xyz/cityu/cs4487/cs4487/"><meta property="twitter:title" content="Part 1 - Introduction | machine learning | rezvan.xyz"><meta property="twitter:description"><meta property="twitter:image" content="https://rezvan.xyz/favicon.ico"><!-- PageFind --><link href="/pagefind/pagefind-ui.css" rel="stylesheet"><script src="/pagefind/pagefind-ui.js"></script><!-- KaTeX support --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script><!-- inline KaTeX --><script>
    function renderKaTeX() {
        if (typeof renderMathInElement !== "undefined") {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "$", right: "$", display: false },
                ],
            });
        }
    }

    document.addEventListener("DOMContentLoaded", renderKaTeX);
    document.addEventListener("astro:after-swap", renderKaTeX);
</script><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script>
    function init() {
        preloadTheme();
        onScroll();
        animate();
        updateThemeButtons();
        addCopyCodeButtons();
        setGiscusTheme();

        const backToTop = document.getElementById("back-to-top");
        backToTop?.addEventListener("click", (event) => scrollToTop(event));

        const backToPrev = document.getElementById("back-to-prev");
        backToPrev?.addEventListener("click", () => window.history.back());

        const lightThemeButton = document.getElementById("light-theme-button");
        lightThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "light");
            toggleTheme(false);
            updateThemeButtons();
        });

        const darkThemeButton = document.getElementById("dark-theme-button");
        darkThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "dark");
            toggleTheme(true);
            updateThemeButtons();
        });

        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );
        systemThemeButton?.addEventListener("click", () => {
            localStorage.setItem("theme", "system");
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
            updateThemeButtons();
        });

        window
            .matchMedia("(prefers-color-scheme: dark)")
            .addEventListener("change", (event) => {
                if (localStorage.theme === "system") {
                    toggleTheme(event.matches);
                }
            });

        document.addEventListener("scroll", onScroll);
    }

    function updateThemeButtons() {
        const theme = localStorage.getItem("theme");
        const lightThemeButton = document.getElementById("light-theme-button");
        const darkThemeButton = document.getElementById("dark-theme-button");
        const systemThemeButton = document.getElementById(
            "system-theme-button",
        );

        function removeActiveButtonTheme(button) {
            button?.classList.remove("bg-black/5");
            button?.classList.remove("dark:bg-white/5");
        }

        function addActiveButtonTheme(button) {
            button?.classList.add("bg-black/5");
            button?.classList.add("dark:bg-white/5");
        }

        removeActiveButtonTheme(lightThemeButton);
        removeActiveButtonTheme(darkThemeButton);
        removeActiveButtonTheme(systemThemeButton);

        if (theme === "light") {
            addActiveButtonTheme(lightThemeButton);
        } else if (theme === "dark") {
            addActiveButtonTheme(darkThemeButton);
        } else {
            addActiveButtonTheme(systemThemeButton);
        }
    }

    function animate() {
        const animateElements = document.querySelectorAll(".animate");

        animateElements.forEach((element, index) => {
            setTimeout(() => {
                element.classList.add("show");
            }, index * 100);
        });
    }

    function onScroll() {
        if (window.scrollY > 0) {
            document.documentElement.classList.add("scrolled");
        } else {
            document.documentElement.classList.remove("scrolled");
        }
    }

    function scrollToTop(event) {
        event.preventDefault();
        window.scrollTo({
            top: 0,
            behavior: "smooth",
        });
    }

    function toggleTheme(dark) {
        const css = document.createElement("style");

        css.appendChild(
            document.createTextNode(
                `* {
             -webkit-transition: none !important;
             -moz-transition: none !important;
             -o-transition: none !important;
             -ms-transition: none !important;
             transition: none !important;
          }
        `,
            ),
        );

        document.head.appendChild(css);

        if (dark) {
            document.documentElement.classList.add("dark");
        } else {
            document.documentElement.classList.remove("dark");
        }

        window.getComputedStyle(css).opacity;
        document.head.removeChild(css);

        setGiscusTheme();
    }

    function preloadTheme() {
        const userTheme = localStorage.theme;

        if (userTheme === "light" || userTheme === "dark") {
            toggleTheme(userTheme === "dark");
        } else {
            toggleTheme(
                window.matchMedia("(prefers-color-scheme: dark)").matches,
            );
        }
    }

    function addCopyCodeButtons() {
        let copyButtonLabel = "üìã";
        let codeBlocks = Array.from(document.querySelectorAll("pre"));

        async function copyCode(codeBlock, copyButton) {
            const codeText = codeBlock.innerText;
            const buttonText = copyButton.innerText;
            const textToCopy = codeText.replace(buttonText, "");

            await navigator.clipboard.writeText(textToCopy);
            copyButton.innerText = "‚úÖ";

            setTimeout(() => {
                copyButton.innerText = copyButtonLabel;
            }, 2000);
        }

        for (let codeBlock of codeBlocks) {
            const wrapper = document.createElement("div");
            wrapper.style.position = "relative";

            const copyButton = document.createElement("button");
            copyButton.innerText = copyButtonLabel;
            copyButton.classList = "copy-code";

            codeBlock.setAttribute("tabindex", "0");
            codeBlock.appendChild(copyButton);

            codeBlock.parentNode.insertBefore(wrapper, codeBlock);
            wrapper.appendChild(codeBlock);

            copyButton?.addEventListener("click", async () => {
                await copyCode(codeBlock, copyButton);
            });
        }
    }

    const setGiscusTheme = () => {
        const giscus = document.querySelector(".giscus-frame");

        const isDark = document.documentElement.classList.contains("dark");

        if (giscus) {
            const url = new URL(giscus.src);
            url.searchParams.set("theme", isDark ? "dark" : "light");
            giscus.src = url.toString();
        }
    };

    document.addEventListener("DOMContentLoaded", () => init());
    document.addEventListener("astro:after-swap", () => init());
    preloadTheme();
</script><link rel="stylesheet" href="/_astro/_subject_.CmU_Tg_r.css">
<style>summary[data-astro-cid-xvrfupwn]{cursor:pointer;border-top-left-radius:.5rem;border-top-right-radius:.5rem;padding:.375rem .75rem;font-weight:500;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}summary[data-astro-cid-xvrfupwn]:hover{background-color:#0000000d}summary[data-astro-cid-xvrfupwn]:hover:is(.dark *){background-color:#ffffff0d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]{background-color:#0000000d}details[data-astro-cid-xvrfupwn][open] summary[data-astro-cid-xvrfupwn]:is(.dark *){background-color:#ffffff0d}
</style><script type="module" src="/_astro/hoisted.DzxSAGjc.js"></script></head> <body> <header data-astro-transition-persist="astro-l7r54iwe-1"> <div class="mx-auto max-w-screen-sm px-3"> <div class="flex flex-wrap justify-between gap-y-2"> <a href="/" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out">  <div class="font-semibold"> rezvan.xyz </div>  </a> <nav class="flex items-center gap-1 text-sm"> <a href="/posts" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> posts </a> <span> / </span> <a href="/chalmers" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> chalmers </a> <span> / </span> <a href="/cityu" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> cityu </a> <span> / </span> <button id="magnifying-glass" aria-label="Search" class="flex items-center rounded border border-black/15 bg-neutral-100 px-2 py-1 text-xs transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:bg-neutral-900 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg height="16" stroke-linejoin="round" viewBox="0 0 16 16" width="16" style="color: currentcolor;"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.5 7C3.5 5.067 5.067 3.5 7 3.5C8.933 3.5 10.5 5.067 10.5 7C10.5 7.88461 10.1718 8.69256 9.63058 9.30876L9.30876 9.63058C8.69256 10.1718 7.88461 10.5 7 10.5C5.067 10.5 3.5 8.933 3.5 7ZM9.96544 11.0261C9.13578 11.6382 8.11014 12 7 12C4.23858 12 2 9.76142 2 7C2 4.23858 4.23858 2 7 2C9.76142 2 12 4.23858 12 7C12 8.11014 11.6382 9.13578 11.0261 9.96544L14.0303 12.9697L14.5607 13.5L13.5 14.5607L12.9697 14.0303L9.96544 11.0261Z" fill="currentColor"></path></svg>
&nbsp;Search
</button> </nav> </div> </div> </header> <main>  <div class="mx-auto max-w-screen-sm px-3"> <div class="animate"> <a href="/cityu/cs4487" class="not-prose group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-7 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm"> Back to machine learning </div> </a> </div> <div class="my-10 space-y-1"> <div class="animate flex items-center gap-1.5"> <div class="font-base text-sm"> CS4487 </div>
&bull;
<div class="font-base text-sm"> <time datetime="2024-09-04T00:00:00.000Z"> September 04, 2024 </time> </div> 
&bull;
<div class="font-base text-sm">
Last modified:  <time datetime="2024-09-06T05:37:25.000Z"> September 06, 2024 </time> </div> 
&bull;
<div class="font-base text-sm"> 14 min read </div> </div> <h1 class="animate text-3xl font-semibold text-black dark:text-white"> Part 1 - Introduction </h1> </div> <details open class="animate rounded-lg border border-black/15 dark:border-white/20" data-astro-cid-xvrfupwn> <summary data-astro-cid-xvrfupwn>Table of Contents</summary> <nav class="" data-astro-cid-xvrfupwn> <ul class="py-3" data-astro-cid-xvrfupwn> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#what-is-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> What is learning? </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#topics-in-machine-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Topics in Machine Learning </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#supervised-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Supervised Learning </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#unsupervised-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Unsupervised Learning </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#reinforcement-learning" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Reinforcement Learning </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#learning-theory" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Learning Theory </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#math-revision" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Math Revision </a> <ul class="translate-x-3"> <li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#linear-algebra" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Linear Algebra </a>  </li> </ul> </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#probability-theory" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Probability Theory </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-classification-task" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Classification Task </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#the-classifier-learning-problem" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> The Classifier Learning Problem </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#classification-error-and-accuracy" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Classification Error and Accuracy </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#k-nearest-neighbors-knn-classifier" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> K-Nearest Neighbors (KNN) Classifier </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#max-vs-arg-max" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Max vs. Arg Max </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#knn-classification" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> KNN Classification </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#brute-force-knn" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Brute Force KNN </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#knn-variants" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> KNN Variants </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#knn-trade-offs" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> KNN Trade-offs </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#probabilistic-classifiers" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Probabilistic Classifiers </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#class-model" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Class Model </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#observation-model" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Observation Model </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#gaussian-distribution" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Gaussian Distribution </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#learn-the-parameters-from-data" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Learn the Parameters from Data </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#bayesian-decision-rule" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Bayesian Decision Rule </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#bayes-rule" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Bayes Rule </a>  </li><li class="list-inside list-disc px-6 py-1.5 text-sm"> <a href="#bayes-classifier-summary" target="_self" class="inline-block decoration-black/30 dark:decoration-white/30 hover:decoration-black/50 focus-visible:decoration-black/50 dark:hover:decoration-white/50 dark:focus-visible:decoration-white/50 text-current hover:text-black focus-visible:text-black dark:hover:text-white dark:focus-visible:text-white transition-colors duration-300 ease-in-out underline underline-offset-[3px]"> Bayes Classifier Summary </a>  </li> </ul> </nav> </details> <article class="animate"> <h3 id="what-is-learning">What is learning?</h3>
<p>Defining <em>learning</em> is a task many people have tried to do during our time. Some examples:</p>
<ul>
<li>
<p><strong>Behaviorism</strong> (Skinner, 1900-1950)</p>
<ul>
<li>Learning is a long-term change in behavior due to experience.</li>
</ul>
</li>
<li>
<p><strong>Cognitivism</strong> (Gestalt School, 1920-):</p>
<ul>
<li>Learning is an internal mental process that integrates new information into established mental frameworks and updates those frameworks over time.</li>
</ul>
</li>
<li>
<p><strong>Connectionism</strong> (Hebb, 1949):</p>
<ul>
<li>Learning is a physical process in which neurons join by developing the synapses between them.</li>
</ul>
</li>
</ul>
<p>This also applies to the definition of <em>machine learning</em>:</p>
<ul>
<li>
<p><strong>Samuel</strong> (1959):</p>
<ul>
<li>Machine learning is a field of study that gives computers the ability to learn without being explicitly programmed.</li>
</ul>
</li>
<li>
<p><strong>Mitchell</strong> (1997):</p>
<ul>
<li>A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.</li>
</ul>
</li>
<li>
<p><strong>Jordan</strong> (2015):</p>
<ul>
<li>It is one of today‚Äôs rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science</li>
</ul>
</li>
</ul>
<h3 id="topics-in-machine-learning">Topics in Machine Learning</h3>
<p>So we‚Äôve seen that we can define learning in many different ways, and as such, there are several ways we can approach machine learning.
Here are some of the topics we will cover:</p>
<ul>
<li>Supervised Learning</li>
<li>Unsupervised Learning</li>
<li>Reinforcement Learning</li>
<li>Learning Theory</li>
</ul>
<h3 id="supervised-learning">Supervised Learning</h3>
<p>We have some sort of task, be it classification or regression, but we have training data that has both the input and the corresponding output.</p>
<p>We try to find the function(s) that best map the input to the output.</p>
<p>Simply, mathematically we can define it as:
$$
f: X \mapsto Y
$$</p>
<p>Where $X$ is the input space and $Y$ is the output space, and we want to find the <em>best</em> function $f$ that maps $X$ to $Y$.</p>
<h3 id="unsupervised-learning">Unsupervised Learning</h3>
<p>In the case that we do not have data that has both the input and the output, we can use unsupervised learning.
The problem itself does not have to differ from a supervised learning problem, but the data we have does not have the output.</p>
<p>In this case, we try to find the structure in the data, and we can do this in several ways:</p>
<ul>
<li>Density estimation:
<ul>
<li>Construct a probability model over the input space.</li>
</ul>
</li>
<li>Clustering:
<ul>
<li>Discover groups of similar examples in the data.</li>
</ul>
</li>
<li>Dimensionality reduction:
<ul>
<li>Project high-dim data to 2 or 3-dimensions (for visualization purposes).</li>
</ul>
</li>
</ul>
<h3 id="reinforcement-learning">Reinforcement Learning</h3>
<p>This approach differs a bit from supervised and unsupervised learning.
In this case, we have an <em>agent</em> that interacts with an <em>environment</em>, and the agent receives rewards or punishments based on its actions.</p>
<p>We make a sequence of actions, given the current states.
E.g. a robot interacting with its environment.
We aim to maximize the reward function over time.
At some point, receive a reward or a punishment, actions may also affect future reward!</p>
<h3 id="learning-theory">Learning Theory</h3>
<p>But, why does machine learning even work in the first place?</p>
<p>From traditional learning theory we know that we have a so-called <em>performance guarantee</em>.
The performance guarantee is a bound on the generalization error, which is the difference between the training error and the test error.</p>
<p>So, the question is not if it will work, it is how well will it work. So the questions we need to figure out are:</p>
<ul>
<li>Which functions can be learned/represented?</li>
<li>How much data do we need?</li>
</ul>
<h3 id="math-revision">Math Revision</h3>
<p>Let‚Äôs quickly revise some math concepts that we will need in this course.</p>
<h4 id="linear-algebra">Linear Algebra</h4>
<p>The definition of a vector space can be defined as:</p>
<blockquote>
<p>The real vector space $\mathbb{R}^N$ is a set with elements $\mathbf{x} = [x_1, x_2, \ldots, x_N]^T$ where each $x_j \in \mathbb{R}$.
The elements $\mathbf{x}$ are called vectors.
Which must satisfy the following properties:</p>
</blockquote>
<ul>
<li>
<p><strong>Addition</strong>: If $\mathbf{x} \in \mathbb{R}^N$ and $\mathbf{y} \in \mathbb{R}^N$, then $\mathbf{x} + \mathbf{y} = [x_1 + y_1, x_2 + y_2, \ldots, x_N + y_N]^T \in \mathbb{R}^N$.</p>
</li>
<li>
<p><strong>Scalar Product</strong>: If $\mathbf{x} \in \mathbb{R}^N$ and $a \in \mathbb{R}$, then $a\mathbf{x} = [ax_1, ax_2, \ldots, ax_N]^T \in \mathbb{R}^N$.</p>
</li>
<li>
<p><strong>Inner Product</strong>: If $\mathbf{x} \in \mathbb{R}^N$ and $\mathbf{y} \in \mathbb{R}^N$, then $\mathbf{x}^T\mathbf{y} = \sum_{j=1}^{N} x_jy_j$.</p>
</li>
</ul>
<p>The definition of a matrix can be defined as:</p>
<blockquote>
<p>A matrix $\mathbf{X} \in \mathbb{R}^{M \times N}$ is rectangular array of elements $x_{ij} \in \mathbb{R}$, $1 \leq i \leq M$, $1 \leq j \leq N$.
$$
\mathbf{X} = \begin{bmatrix}
x_{11} &#x26; x_{12} &#x26; \ldots &#x26; x_{1N} \newline
x_{21} &#x26; x_{22} &#x26; \ldots &#x26; x_{2N} \newline
\vdots &#x26; \vdots &#x26; \ddots &#x26; \vdots \newline
x_{M1} &#x26; x_{M2} &#x26; \ldots &#x26; x_{MN}
\end{bmatrix}
$$</p>
</blockquote>
<p>A matrix $\mathbf{X} \in \mathbb{R}^{M \times N}$ supports the following operations:</p>
<ul>
<li><strong>Addition</strong>: If $\mathbf{X} \in \mathbb{R}^{M \times N}$ and $\mathbf{Y} \in \mathbb{R}^{M \times N}$, then $\mathbf{Z} = \mathbf{X} + \mathbf{Y} \in \mathbb{R}^{M \times N}$ where $z_{ij} = x_{ij} + y_{ij}$.</li>
<li><strong>Scalar Product</strong>: If $\mathbf{X} \in \mathbb{R}^{M \times N}$ and $a \in \mathbb{R}$, then $\mathbf{Y} = a\mathbf{X} \in \mathbb{R}^{M \times N}$ where $y_{ij} = ax_{ij}$.</li>
<li><strong>Matrix Product</strong>: If $\mathbf{X} \in \mathbb{R}^{M \times N}$ and $\mathbf{Y} \in \mathbb{R}^{N \times P}$, then $\mathbf{Z} = \mathbf{X}\mathbf{Y} \in \mathbb{R}^{M \times P}$ where $z_{ij} = \sum_{k=1}^{N} x_{ik}y_{kj}$.</li>
</ul>
<h3 id="probability-theory">Probability Theory</h3>
<p>Let‚Äôs start with the definition of a probability distribution:</p>
<blockquote>
<p>A probability distribution $p$ over a sample space $\Omega$ is a <strong>function</strong> from elements/subsets of $\Omega$ to the real numbers, that satisfies the following conditions:</p>
</blockquote>
<ul>
<li><strong>Non-negativity</strong>: $p(\omega) \geq 0$ for all $\omega \subseteq \Omega$.</li>
<li><strong>Normalization</strong>: $\sum_{\omega \in \Omega} p(\omega) = 1$.</li>
<li><strong>Additivity</strong>: For all $\omega$, $\omega^\prime \subseteq \Omega$ that are <strong>disjoint</strong> sets, $p(\omega \bigcup \omega^\prime) = p(\omega) + p(\omega^\prime)$.</li>
</ul>
<p>Let‚Äôs define a random variable now:</p>
<blockquote>
<p>A random variable $X$ is defined by a <strong>function</strong> $f_x$ that maps each element $\omega$ of the sample space $\Omega$ to a value $x = f_x(\omega)$ in a set $\chi$ (called the range of the random variable). <br> <br>
For each $x \in \chi$, the <strong>event</strong> $\{X = x\}$ refers to the subset of the sample space $\{\omega | \omega \in \Omega, f_x(\omega) = x\}$. <br> <br>
For each $x \in \chi$, the probability $p(X = x) = p({\omega | \omega \in \Omega, f_x(\omega) = x})$.</p>
</blockquote>
<p>We can also specify a probability distribution for a random variable $X$ with range $\chi$ directly instead of via an underlying sample space $\Omega$.</p>
<p>The following conditions must hold:</p>
<ul>
<li><strong>Discrete probability mass function</strong>:
<ul>
<li>$p(X = x) \geq 0 \quad \forall x \in \chi$ and $\sum_{x \in \chi} p(X = x) = 1$.</li>
</ul>
</li>
<li><strong>Continuous probability density function</strong>:
<ul>
<li>$p(X = x) \geq 0 \quad \forall x \in \chi$ and $\int_{\chi} p(X = x)dx = 1$.</li>
</ul>
</li>
</ul>
<p>Let‚Äôs now look at classification from a mathematical perspective.</p>
<h3 id="the-classification-task">The Classification Task</h3>
<p>The definition of a classification task can be defined as:</p>
<blockquote>
<p>Given a feature vector $\mathbf{x} \in \mathbb{R}^N$ that describes an object that belongs to one of $C$ classes from the set $\mathcal{Y}$,
predict which class the object belongs to.</p>
</blockquote>
<p>A classical example is iris classification, where we have 3 classes of iris flowers.
We‚Äôre given two features, the petal length and the sepal width, and we want to predict the class of the iris.
$$
\mathbf{x} = \begin{bmatrix}
\text{petal length} \newline
\text{sepel width}
\end{bmatrix}
= \begin{bmatrix}
x_1 \newline
x_2
\end{bmatrix}
\in \mathbb{R}^2
$$</p>
<p>$$
\mathcal{Y} = \{ \text{‚Äúversicolor‚Äù}, \text{‚Äúsetosa‚Äù}, \text{‚Äúvirginica‚Äù} \}, \text{where } |\mathcal{Y}| = C = 3
$$</p>
<p>or with numbers:
$$
\mathcal{Y} = \{ 0, 1, 2 \}
$$</p>
<h3 id="the-classifier-learning-problem">The Classifier Learning Problem</h3>
<p>The definition of the classifier learning problem can be defined as:</p>
<blockquote>
<p>Given a data set of example pairs $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$
where $\mathbf{x}^{(i)} \in \mathbb{R}^N$ is a feature vector and $y^{(i)} \in \mathcal{Y} = \{1, \ldots, C\}$ is the class label,
learn a function $f: \mathbb{R}^N \mapsto \mathcal{Y}$ that accurately predicts the class label $y$ for any feature vector $\mathbf{x}$.</p>
</blockquote>
<p>Let‚Äôs define the indicator function:
$$
\mathbb{I}[A] = \begin{cases}
1 &#x26; \text{if } A \text{ is true} \newline
0 &#x26; \text{otherwise}
\end{cases}
$$</p>
<h3 id="classification-error-and-accuracy">Classification Error and Accuracy</h3>
<p>Let‚Äôs define the classification error:</p>
<blockquote>
<p>Given a data set of example pairs $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$ and a function $f: \mathbb{R}^N \mapsto \mathcal{Y}$,
the classification error rate of $f$ on $\mathcal{D}$ is defined as:
$$
Err(f, \mathcal{D}) = \frac{1}{M} \sum_{i=1}^{M} \mathbb{I}[y^{(i)} \neq f(\mathbf{x}^{(i)})]
$$</p>
</blockquote>
<p>The classification accuracy is then defined as:</p>
<blockquote>
<p>Given a data set of example pairs $\mathcal{D} = \{ (\mathbf{x}^{(i)}, y^{(i)}), i = 1, \ldots, M \}$ and a function $f: \mathbb{R}^N \rightarrow \mathcal{Y}$,
the classification accuracy of $f$ on $\mathcal{D}$ is defined as:
$$
Acc(f, \mathcal{D}) = \frac{1}{M} \sum_{i=1}^{M} \mathbb{I}[y^{(i)} = f(\mathbf{x}^{(i)})] = 1 - Err(f, \mathcal{D})
$$</p>
</blockquote>
<h3 id="k-nearest-neighbors-knn-classifier">K-Nearest Neighbors (KNN) Classifier</h3>
<p>The KNN classifier is a simple classifier that classifies a new example based on the majority class of its $k$ nearest neighbors.</p>
<p>It stores the training set $\mathcal{D}$ and classifies each <strong>new</strong> instance $\mathbf{x}$ using a majority vote of its $K$ nearest neighbors.
$$
\mathcal{N}_K(\mathbf{x}) \subset \{1, \ldots, M\}
$$</p>
<p>Use of the KNN requires choosing the distance function $d : \mathbb{R}^N \times \mathbb{R}^N \mapsto \mathbb{R}$ and the number of neighbors $K$.</p>
<h3 id="max-vs-arg-max">Max vs. Arg Max</h3>
<p>The max operator of a function $f(\mathbf{x})$ defined over $\mathbf{x} \in \mathcal{D}$ returns the maximum value of the function:
$$
\max_{\mathbf{x}} f(\mathbf{x}) = \{f(\mathbf{x}) | \mathbf{x} \in \mathcal{D} \land \forall \mathbf{y} \in \mathcal{D}, f(\mathbf{y}) \leq f(\mathbf{x})\}
$$</p>
<p>The arg max operator of a function $f(\mathbf{x})$ defined over $\mathbf{x} \in \mathcal{D}$ gives the set of points which $f(\mathbf{x})$ reaches the maximum value:
$$
\underset{\mathbf{x}}{\arg\max} f(\mathbf{x}) = \{\mathbf{x} | \mathbf{x} \in \mathcal{D} \land \forall \mathbf{y} \in \mathcal{D}, f(\mathbf{y}) \leq f(\mathbf{x})\}
$$</p>
<h3 id="knn-classification">KNN Classification</h3>
<p>$$
f_{KNN}(\mathbf{x}) = \underset{c \in {1, \ldots, C}}{\arg\max} \sum_{i \in \mathcal{N}_K(\mathbf{x})} \mathbb{I}[y^{(i)} = c]
$$</p>
<p>In general, KNN can work with any distance function $d$ satisfying non-negativity $d(\mathbf{x}, \mathbf{x}^\prime) \geq 0$ and identity of indiscernibles $d(\mathbf{x}, \mathbf{x}) = 0$.</p>
<p>Genrally, the more structure the distance function has (symmetry, triangle inequality, etc.), the more strucutre you can exploit when designing algorithms.</p>
<p>The Minowski distance ($\ell_p$ norm) is defined as:</p>
<blockquote>
<p>Given two data vectors $\mathbf{x}, \mathbf{x}^\prime \in \mathbb{R}^N$, the Minowski distance with parameter $p$ (the $\ell_p$ norm) is a proper metric defined as:
$$
d_p(\mathbf{x}, \mathbf{x}^\prime) = \lVert \mathbf{x} - \mathbf{x}^\prime \rVert_p \newline
= \left( \sum_{j=1}^{N} |x_j - x^{\prime}_j|^p \right)^{\frac{1}{p}}
$$</p>
</blockquote>
<p>Special cases include, Euclidean distance ($p = 2$), Manhattan distance ($p = 1$), and Chebyshev distance ($p = \infty$).</p>
<h3 id="brute-force-knn">Brute Force KNN</h3>
<p>Given any distance function $d$, brute force KNN works by computing the distance $d_i = d(\mathbf{x}^{(i)}, \mathbf{x})$ from a target point $\mathbf{x}$ to all of the training points $\mathbf{x}^{(i)}$.</p>
<p>Sort the distances $\{d_i, i = 1, \ldots, M\}$ and choose the data cases with the $K$ smallest distances to form the neighbor <strong>index</strong> set $\mathcal{N}_K(\mathbf{x})$.</p>
<p>Once the $K$ neighbors are selected, applying the classification rule is easy.</p>
<h3 id="knn-variants">KNN Variants</h3>
<p>Instead of giving all of the $K$ neighbors equal weight in the majority vote, a distance-weighted majority can be used:
$$
f_{KNN}(\mathbf{x}) = \underset{c \in {1, \ldots, C}}{\arg\max} \frac{\sum  w_i \mathbb{I}[y^{(i)} = c]}{\sum w_i} \newline
w_i = exp(-\alpha d_i)
$$</p>
<p>Instead of a brute force nearest neighbor search, data structures like $K$-d trees can be constructed over the training data that support nearest neighbor search with lower computational complexity.</p>
<h3 id="knn-trade-offs">KNN Trade-offs</h3>
<ul>
<li>Advantages:
<ul>
<li>No training period is involved (i.e., lazy learning), and new data can be added seamlessly without re-training the model</li>
<li>Converges to the correct decision surface as data goes to infinity</li>
</ul>
</li>
<li>Disadvantages:
<ul>
<li>Does not work well with large datasets. Since KNN needs to store all training data, performing neighbor search requires a lot of memory and takes a lot of time</li>
<li>Does not work well with high dimensions. It becomes difficult for KNN to calculate the distance in each dimension. Moreover, everything is far from everything else in high dimensions (the so-called ‚Äúcurse of dimensionality‚Äù)</li>
</ul>
</li>
</ul>
<h3 id="probabilistic-classifiers">Probabilistic Classifiers</h3>
<p>Probabilistic classifiers are classifiers that output a probability distribution over the classes.</p>
<p>For example, <strong>generative</strong> models are probabilistic classifiers.</p>
<p>Each object/pattern has a particular (and possibly unique) probability distribution over the classes.</p>
<h3 id="class-model">Class Model</h3>
<p>As we‚Äôve defined it before, possible classes are $\mathcal{Y}$.
In the real world, the frequency that class $y$ occurs is given by the probabalistic distribution $p(y)$.</p>
<p>$p(y)$ is called the <strong>prior distribution</strong>.</p>
<h3 id="observation-model">Observation Model</h3>
<p>We measure/observe feature vector $\mathbf{x}$. The value of the features <strong>depends</strong> on the class.</p>
<p>The observation is drawn according to the distribution $p(\mathbf{x} | y)$.</p>
<p>$p(\mathbf{x} | y)$ is called the <strong>class conditional distribution</strong>.
It indicates the probability of observing a particular feature vector $\mathbf{x}$ given that the class is $y$.</p>
<h3 id="gaussian-distribution">Gaussian Distribution</h3>
<p>Each class is modeled as a separate Gaussian distribution of the feature value.</p>
<p>$$
p(x | y = c; \mu_c, \sigma_{c}^2) = \frac{1}{\sqrt{2\pi\sigma_c^2}} \exp \left( -\frac{(x - \mu_c)^2}{2\sigma_c^2} \right)
$$</p>
<p>Each class has its own mean $\mu_c$ and variance $\sigma_c^2$.</p>
<h3 id="learn-the-parameters-from-data">Learn the Parameters from Data</h3>
<p>Maximum likelihood estimation (MLE) is used to estimate the parameters of the Gaussian distribution.</p>
<p>Set the parameters $(\mu_c, \sigma_c^2)$ to maximize the likelihood (probability) of the samples for class $c$.</p>
<p>Let $\mathcal{D}_c = \{x^{(i)} | y^{(i)}\}$ for $i = 1, \ldots, M_c$ be the data for class $c$.</p>
<p>The likelihood of the data is:
$$
(\hat{\mu}_c, \hat{\sigma}_c^2) = \underset{\mu_c, \sigma_c^2}{\arg\max} \sum \log p(x^{(i)} | y^{(i)}; \mu_c, \sigma_c^2)
$$</p>
<p>When we view the above objective as a function of the parameters $\{\mu_c, \sigma_c^2\}$, we instead call it the likelihood function of the data.</p>
<p>Sample mean:
$$
\hat{\mu}_c = \frac{1}{M} \sum x^{(i)}
$$</p>
<p>Sample variance:
$$
\hat{\sigma}_c^2 = \frac{1}{M_c} \sum (x^{(i)} - \hat{\mu}_c)^2
$$</p>
<h3 id="bayesian-decision-rule">Bayesian Decision Rule</h3>
<p>The Bayesian decision rule (BDR) makes the <strong>optimal</strong> decisions on problems involving probability (uncertainty).
It minimizes the probability of making a prediction error.</p>
<p>We call this the <strong>Bayes Optimal Classifier</strong>.</p>
<p>Given observation $\mathbf{x}$, pick the class $c$ with the <strong>largest posterior probability</strong> $p(y = c | \mathbf{x})$.
$$
f_{B}(\mathbf{x}) = \underset{c \in \{1, \ldots, C\}}{\arg\max} p(y = c | \mathbf{x})
$$</p>
<p>But there is a problem, we don‚Äôt have $p(y | \mathbf{x})$, we only have $p(y)$ and $p(\mathbf{x} | y)$.</p>
<h3 id="bayes-rule">Bayes Rule</h3>
<p>The posterior probability can be calculated using Bayes rule:
$$
p(y | \mathbf{x}) = \frac{p(\mathbf{x} | y) p(y)}{p(\mathbf{x})}
$$</p>
<p>The denominator is the probability of $\mathbf(x)$,
$$
p(\mathbf{x}) = \sum_{y in \mathcal{Y}} p(\mathbf{x}, y) = \sum_{y \in \mathcal{Y}} p(\mathbf{x} | y) p(y)
$$</p>
<p>The denominator makes $p(y | \mathbf{x})$ sum to 1.</p>
<p>So, we can write it as:
$$
p(y | \mathbf{x}) = \frac{p(\mathbf{x} | y) p(y)}{\sum_{y \in \mathcal{Y}} p(\mathbf{x} | y) p(y)}
$$</p>
<h3 id="bayes-classifier-summary">Bayes Classifier Summary</h3>
<p>For training, we collect training data from each class. For each class $c$, we estimate the class conditional densities $p(x | y = c)$:</p>
<ol>
<li>Select a form of the distribution (e.g., Gaussian)</li>
<li>Estimate its parameters with MLE</li>
<li>Estimate the class priors $p(y)$ using MLE</li>
</ol>
<p>For classification, given a new sample $\mathbf{x}^\star$, calculate the likelihood $p(\mathbf{x}^\star | y = c)$ for each class $c$.
Pick the class $c$ with the largest posterior probability $p(y = c | \mathbf{x}^\star)$.</p>
<p>Equivalently, use $p(\mathbf{x}^\star | y = c)p(y = c)$ or $\log p(\mathbf{x}^\star | y = c) + \log p(y = c)$.</p> <div class="mt-24"> <div class="grid grid-cols-2 gap-1.5 sm:gap-3"> <div class="invisible"></div> <div class="invisible"></div> </div> </div> <div class="mt-24"> <div class="giscus"></div> <script data-astro-rerun src="https://giscus.app/client.js" data-repo="rezaarezvan/rezvan.xyz" data-repo-id="R_kgDOHvQr3w" data-category="General" data-category-id="DIC_kwDOHvQr384CiWVC" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" data-loading="lazy" crossorigin="anonymous" async></script> </div> </article> </div>  </main> <footer class="animate"> <div class="mx-auto max-w-screen-sm px-3"> <div class="relative"> <div class="absolute -top-12 right-0"> <button id="back-to-top" class="group relative flex w-fit flex-nowrap rounded border border-black/15 py-1.5 pl-8 pr-3 transition-colors duration-300 ease-in-out hover:bg-black/5 hover:text-black focus-visible:bg-black/5 focus-visible:text-black dark:border-white/20 dark:hover:bg-white/5 dark:hover:text-white dark:focus-visible:bg-white/5 dark:focus-visible:text-white"> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="absolute left-2 top-1/2 size-4 -translate-y-1/2 rotate-90 fill-none stroke-current stroke-2"> <line x1="5" y1="12" x2="19" y2="12" class="translate-x-2 scale-x-0 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-hover:scale-x-100 group-focus-visible:translate-x-0 group-focus-visible:scale-x-100"></line> <polyline points="12 5 5 12 12 19" class="translate-x-1 transition-transform duration-300 ease-in-out group-hover:translate-x-0 group-focus-visible:translate-x-0"></polyline> </svg> <div class="text-sm">Back to top</div> </button> </div> </div> <div class="flex items-center justify-between"> <div>&copy; 2024 ‚Ä¢ rezvan.xyz </div> <div class="flex flex-wrap items-center gap-1.5"> <button id="light-theme-button" aria-label="Light theme" class="group flex size-9 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <circle cx="12" cy="12" r="5"></circle> <line x1="12" y1="1" x2="12" y2="3"></line> <line x1="12" y1="21" x2="12" y2="23"></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line> <line x1="1" y1="12" x2="3" y2="12"></line> <line x1="21" y1="12" x2="23" y2="12"></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line> </svg> </button> <button id="dark-theme-button" aria-label="Dark theme" class="group flex size-9 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path> </svg> </button> <button id="system-theme-button" aria-label="System theme" class="group flex size-9 items-center justify-center rounded border border-black/15 hover:bg-black/5 focus-visible:bg-black/5 dark:border-white/20 dark:hover:bg-white/5 dark:focus-visible:bg-white/5"> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="transition-colors duration-300 ease-in-out group-hover:animate-pulse group-hover:stroke-black group-focus-visible:animate-pulse group-focus-visible:stroke-black group-hover:dark:stroke-white dark:group-focus-visible:stroke-white"> <rect x="2" y="3" width="20" height="14" rx="2" ry="2"></rect> <line x1="8" y1="21" x2="16" y2="21"></line> <line x1="12" y1="17" x2="12" y2="21"></line> </svg> </button> </div> </div> </div> </footer> <aside data-pagefind-ignore> <div id="backdrop" class="bg-[rgba(0, 0, 0, 0.5] invisible fixed left-0 top-0 z-50 flex h-screen w-full justify-center p-6 backdrop-blur-sm" data-astro-transition-persist="astro-3snakcvo-2"> <div id="pagefind-container" class="m-0 flex h-fit max-h-[80%] w-full max-w-screen-sm flex-col overflow-auto rounded border border-black/15 bg-neutral-100 p-2 px-4 py-3 shadow-lg dark:border-white/20 dark:bg-neutral-900"> <div id="search" class="pagefind-ui pagefind-init" data-pagefind-ui data-bundle-path="/pagefind/" data-ui-options="{&#34;showImages&#34;:false,&#34;excerptLength&#34;:15,&#34;resetStyles&#34;:false}"></div>  <div class="mr-2 pb-1 pt-4 text-right text-xs dark:prose-invert">
Press <span class="prose text-xs dark:prose-invert"><kbd class="">Esc</kbd></span> or click anywhere to close
</div> </div> </div> </aside> <script>
  const magnifyingGlass = document.getElementById("magnifying-glass");
  const backdrop = document.getElementById("backdrop");

  function openPagefind() {
    const searchDiv = document.getElementById("search");
    const search = searchDiv.querySelector("input");
    setTimeout(() => {
      search.focus();
    }, 0);
    backdrop?.classList.remove("invisible");
    backdrop?.classList.add("visible");
  }

  function closePagefind() {
    const search = document.getElementById("search");
    search.value = "";
    backdrop?.classList.remove("visible");
    backdrop?.classList.add("invisible");
  }

  // open pagefind
  magnifyingGlass?.addEventListener("click", () => {
    openPagefind();
  });

  document.addEventListener("keydown", (e) => {
    if (e.key === "/") {
      e.preventDefault();
      openPagefind();
    } else if ((e.metaKey || e.ctrlKey) && e.key === "k") {
      e.preventDefault();
      openPagefind();
    }
  });

  // close pagefind
  document.addEventListener("keydown", (e) => {
    if (e.key === "Escape" || e.keyCode === 27) {
      closePagefind();
    }
  });

  // close pagefind when searched result(link) clicked
  document.addEventListener("click", (event) => {
    if (event.target.classList.contains("pagefind-ui__result-link")) {
      closePagefind();
    }
  });

  backdrop?.addEventListener("click", (event) => {
    if (!event.target.closest("#pagefind-container")) {
      closePagefind();
    }
  });

  // prevent form submission
  const form = document.getElementById("form");
  form?.addEventListener("submit", (event) => {
    event.preventDefault();
  });
</script>  </body></html>